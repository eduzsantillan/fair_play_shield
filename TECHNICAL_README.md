# Fair Play Shield â€” DocumentaciÃ³n TÃ©cnica Completa

## QuÃ© se hizo, cÃ³mo se implementÃ³ y cÃ³mo el modelo llega a sus conclusiones

---

## 1. Â¿QuÃ© es el Match Integrity Score (MIS)?

El MIS es un nÃºmero de **0 a 100** que se asigna a cada partido de fÃºtbol. Representa quÃ© tan "estadÃ­sticamente anÃ³malo" es ese partido comparado con el comportamiento normal del fÃºtbol europeo.

- **0** = el partido se comportÃ³ exactamente como se esperaba (cuotas normales, goles normales, tarjetas normales)
- **100** = el partido presenta la combinaciÃ³n mÃ¡s extrema posible de anomalÃ­as estadÃ­sticas

**MIS NO significa "partido amaÃ±ado"**. Significa: "este partido tiene suficientes seÃ±ales estadÃ­sticas inusuales como para merecer que alguien lo investigue". Es una herramienta de priorizaciÃ³n, no de acusaciÃ³n.

El MIS se genera combinando 3 modelos de Machine Learning que analizan 12 variables (features) calculadas a partir de datos reales de cuotas de apuestas y estadÃ­sticas del partido.

**Nota**: "Match Integrity Score" es un nombre propio de este proyecto, no un estÃ¡ndar de la industria. El concepto equivalente existe en organizaciones profesionales bajo otros nombres: Sportradar (proveedor oficial de FIFA/UEFA) lo llama **Fraud Detection System (FDS)**, la UEFA lo llama **Betting Fraud Detection System (BFDS)**, y la IBIA lo llama **Suspicious Betting Alert**. Todos aplican el mismo principio: combinar datos de cuotas de apuestas con estadÃ­sticas del partido para generar un nivel de sospecha. Nuestro MIS es una implementaciÃ³n acadÃ©mica simplificada de ese mismo concepto.

---

## 2. LibrerÃ­as y dependencias del proyecto

Archivo: `requirements.txt`

| LibrerÃ­a                    | VersiÃ³n                    | Para quÃ© se usa                                                                                     |
| --------------------------- | -------------------------- | --------------------------------------------------------------------------------------------------- |
| `pandas`                    | >=2.0.0                    | ManipulaciÃ³n de datos tabulares (DataFrames)                                                        |
| `numpy`                     | >=1.24.0                   | Operaciones numÃ©ricas y arrays                                                                      |
| `requests`                  | >=2.31.0                   | Descargar datos de APIs (ESPN, football-data.co.uk)                                                 |
| `beautifulsoup4`            | >=4.12.0                   | Parseo de HTML (scraping auxiliar)                                                                  |
| `scipy`                     | >=1.11.0                   | Tests estadÃ­sticos (Shapiro-Wilk, Mann-Whitney, Z-Score)                                            |
| `statsmodels`               | >=0.14.0                   | AnÃ¡lisis estadÃ­stico avanzado                                                                       |
| `scikit-learn`              | >=1.3.0                    | Los 3 modelos ML (Isolation Forest, Random Forest, Logistic Regression) + StandardScaler + mÃ©tricas |
| `plotly`                    | >=5.18.0                   | GrÃ¡ficos interactivos del dashboard                                                                 |
| `dash`                      | >=2.14.0                   | Framework web del dashboard (servidor local)                                                        |
| `dash-bootstrap-components` | >=1.5.0                    | Componentes visuales (cards, tabs, badges) del dashboard                                            |
| `psycopg2-binary`           | >=2.9.0                    | ConexiÃ³n a PostgreSQL                                                                               |
| `sqlalchemy`                | >=2.0.0                    | ORM para PostgreSQL                                                                                 |
| `python-dotenv`             | >=1.0.0                    | Variables de entorno (.env)                                                                         |
| `seaborn`                   | >=0.13.0                   | GrÃ¡ficos estadÃ­sticos del EDA                                                                       |
| `matplotlib`                | >=3.8.0                    | GrÃ¡ficos base del EDA                                                                               |
| `openpyxl`                  | >=3.1.0                    | Lectura de archivos Excel                                                                           |
| `lxml`                      | >=4.9.0                    | Parser XML/HTML rÃ¡pido                                                                              |
| `html5lib`                  | >=1.1                      | Parser HTML alternativo                                                                             |
| `joblib`                    | (incluido en scikit-learn) | SerializaciÃ³n de modelos entrenados (.pkl)                                                          |

---

## 3. CÃ³mo ejecutar el proyecto localmente

### Paso 0: Requisitos previos

- Python 3.9 o superior
- pip (gestor de paquetes de Python)
- ConexiÃ³n a internet (para descargar datos la primera vez)

### Paso 1: Instalar dependencias

```bash
cd /Users/eduzuniga/Development/mioti/fair_play_shield
pip install -r requirements.txt
```

### Paso 2: Descargar datos y procesarlos

```bash
python main.py --step all --seasons 3
```

Esto ejecuta:

- Descarga de 10 ligas europeas desde football-data.co.uk (CSVs con cuotas)
- Descarga de Europa League desde ESPN API (471+ partidos)
- Limpieza de datos (elimina duplicados, normaliza columnas, parsea fechas)
- CÃ¡lculo de forma de equipos (racha, promedio de goles)
- CÃ¡lculo de features de cuotas (movimiento aperturaâ†’cierre, probabilidad implÃ­cita)
- GeneraciÃ³n de los 7 flags de anomalÃ­a

### Paso 3: AnÃ¡lisis exploratorio (opcional)

```bash
python notebooks/01_eda.py
```

Genera grÃ¡ficos en `data/eda_output/` y muestra tests estadÃ­sticos en consola.

### Paso 4: Entrenar modelos y generar scores

```bash
python models/integrity_scorer.py
```

Entrena los 3 modelos, genera el MIS para cada partido, y guarda:

- Modelos serializados en `models/trained/*.pkl`
- Scores en `data/processed/integrity_scores.csv`

### Paso 5: Lanzar el dashboard

```bash
python dashboard/app.py
```

Abre el navegador en **http://localhost:8050**

---

## 4. Â¿En quÃ© parte del cÃ³digo estÃ¡ cada flag?

### Los flags se calculan en 2 archivos:

**Archivo 1**: `processing/data_cleaning.py` â†’ funciÃ³n `flag_anomalies()` (lÃ­nea 138)

| Flag                      | LÃ­nea exacta   | CÃ³digo                                                        |
| ------------------------- | -------------- | ------------------------------------------------------------- |
| `flag_odds_movement`      | lÃ­nea 142      | `(df["odds_movement_abs_max"].abs() > 0.15).astype(int)`      |
| `flag_result_surprise`    | lÃ­nea 145      | `df["result_surprise"]` (calculada previamente en el scraper) |
| `flag_streak_break`       | lÃ­neas 148-150 | `(df["home_win_streak"] >= 5) & (df["result"] == "A")`        |
| `flag_goals_anomaly_home` | lÃ­neas 153-155 | `df["home_goals"] > df["home_avg_goals_scored"] * 4`          |
| `flag_goals_anomaly_away` | lÃ­neas 156-158 | `df["away_goals"] > df["away_avg_goals_scored"] * 4`          |
| `flag_ht_result_changed`  | lÃ­nea 161      | `df["ht_result_changed"]` (calculada en el scraper)           |
| `flag_cards_anomaly`      | lÃ­neas 164-169 | `(df["total_cards"] - mean_cards) / std_cards > 2`            |
| `total_flags`             | lÃ­nea 173      | `flags[flag_cols].sum(axis=1)` (suma de todos los flags)      |

**Archivo 2**: `ingestion/scrapers/european_leagues_scraper.py` â†’ funciÃ³n `compute_odds_features()` (lÃ­nea 147)

| Variable de soporte            | LÃ­nea     | CÃ³digo                                                |
| ------------------------------ | --------- | ----------------------------------------------------- |
| `odds_movement_home/draw/away` | lÃ­nea 164 | `(df[close_col] - df[open_col]) / df[open_col]`       |
| `odds_movement_abs_max`        | lÃ­nea 167 | `df[move_cols].abs().max(axis=1)`                     |
| `result_surprise`              | lÃ­nea 181 | `(df["result"] != df["expected_result"]).astype(int)` |

**Archivo 3**: `processing/data_cleaning.py` â†’ funciÃ³n `compute_team_form()` (lÃ­nea 47)

| Variable de soporte     | LÃ­nea        | CÃ³digo                                    |
| ----------------------- | ------------ | ----------------------------------------- |
| `home_win_streak`       | lÃ­neas 79-84 | Cuenta victorias consecutivas hacia atrÃ¡s |
| `home_avg_goals_scored` | lÃ­nea 96     | `goals_for / max(total_partidos, 1)`      |
| `away_avg_goals_scored` | lÃ­nea 98     | Idem para visitante                       |

**Los umbrales de cada flag estÃ¡n definidos en**: `config/settings.py` (lÃ­neas 40-43)

```
ODDS_MOVEMENT_SUSPICIOUS_PCT = 0.15      â†’ 15% para flag_odds_movement
MIN_WIN_STREAK_FOR_UPSET_FLAG = 5        â†’ 5 victorias para flag_streak_break
GOALS_ANOMALY_MULTIPLIER = 4             â†’ Ã—4 para flag_goals_anomaly
XG_DEVIATION_THRESHOLD = 2.0             â†’ Z > 2 para flag_cards_anomaly
```

---

## 5. AclaraciÃ³n sobre el movimiento de cuotas (apertura vs cierre)

> **Pregunta del usuario**: "El movimiento de apertura y cierre de casas de apuestas puede deberse a que si un equipo ya estÃ¡ ganando 3 a 0, la cuota de que ese equipo gane disminuirÃ¡ notoriamente."

Esta es una observaciÃ³n muy vÃ¡lida, pero hay una distinciÃ³n importante:

### Las cuotas que usamos NO son "en vivo" (in-play)

- **Cuota de apertura** (`ps_home`): es la cuota que Pinnacle publica cuando abre el mercado para ese partido, tÃ­picamente **3-7 dÃ­as antes del partido**. El partido aÃºn no ha empezado.
- **Cuota de cierre** (`ps_close_home`): es la cuota de Pinnacle en el **momento exacto en que arranca el partido** (pitido inicial). El partido tampoco ha empezado aÃºn.

Ambas cuotas son **pre-partido**. El balÃ³n NO ha rodado todavÃ­a cuando se toma la cuota de cierre. Por lo tanto, el escenario de "ya van ganando 3-0" no aplica a nuestros datos.

### Â¿QuÃ© causa un movimiento legÃ­timo de cuotas pre-partido?

- Una lesiÃ³n de un jugador clave anunciada el dÃ­a del partido
- Condiciones climÃ¡ticas adversas
- AlineaciÃ³n sorpresa anunciada 1 hora antes
- El equipo ya estÃ¡ clasificado y no tiene motivaciÃ³n

Estos movimientos suelen ser del **5-10%**. Nuestro umbral de alerta es **>15%**, que es un movimiento mucho mÃ¡s agresivo que sÃ³lo puede explicarse por un volumen inusual de dinero entrando al mercado en una direcciÃ³n especÃ­fica â€” lo cual es la seÃ±al clÃ¡sica de "dinero informado" (smart money) asociada a amaÃ±os.

### Resumen

| Tipo de cuota           | Momento                          | Â¿Se usa en este proyecto? |
| ----------------------- | -------------------------------- | ------------------------- |
| Cuota de apertura       | DÃ­as antes del partido           | âœ… SÃ­                     |
| Cuota de cierre         | Minutos antes del pitido inicial | âœ… SÃ­                     |
| Cuota in-play (en vivo) | Durante el partido               | âŒ No                     |

---

## 6. La variable `total_flags` â€” ExplicaciÃ³n detallada

### Â¿QuÃ© es?

`total_flags` es simplemente **la suma aritmÃ©tica** de los 7 flags binarios de un partido. Cada flag vale 0 o 1, asÃ­ que `total_flags` puede ir de 0 a 7.

### Ejemplo concreto

Imaginemos un partido Equipo A vs Equipo B:

| Flag                      | Valor | RazÃ³n                                                 |
| ------------------------- | ----- | ----------------------------------------------------- |
| `flag_odds_movement`      | 1     | Las cuotas se movieron un 22%                         |
| `flag_result_surprise`    | 1     | El mercado esperaba victoria local, ganÃ³ el visitante |
| `flag_streak_break`       | 0     | El local no tenÃ­a racha de 5+ victorias               |
| `flag_goals_anomaly_home` | 0     | El local marcÃ³ 1 gol (dentro de su promedio)          |
| `flag_goals_anomaly_away` | 1     | El visitante marcÃ³ 4 goles (promedia 0.8)             |
| `flag_ht_result_changed`  | 1     | Al descanso iba 1-0 (H), terminÃ³ 1-4 (A)              |
| `flag_cards_anomaly`      | 0     | 4 tarjetas (dentro de lo normal)                      |
| **total_flags**           | **4** | Suma: 1+1+0+0+1+1+0                                   |

Este partido tiene `total_flags = 4`, lo cual es muy inusual (solo el 0.6% de partidos llegan a 4).

### Â¿QuÃ© significa "anomalÃ­as simultÃ¡neas"?

**NO significa flags "seguidos" en el tiempo ni en partidos consecutivos**. Significa que **en un mismo partido** coinciden mÃºltiples seÃ±ales de anomalÃ­a al mismo tiempo. Es decir:

- El movimiento de cuotas fue raro **Y**
- El resultado fue sorpresa **Y**
- Los goles fueron anÃ³malos **Y**
- El resultado cambiÃ³ entre tiempos

Todo eso le pasÃ³ **al mismo partido en la misma fecha**. La coincidencia de mÃºltiples anomalÃ­as en un solo evento es lo que genera sospecha, no la secuencia temporal entre partidos diferentes.

### DistribuciÃ³n observada

| total_flags | Partidos | %     | InterpretaciÃ³n                                                   |
| ----------- | -------- | ----- | ---------------------------------------------------------------- |
| 0           | 2,255    | 22.8% | Partido completamente normal                                     |
| 1           | 4,326    | 43.8% | Un indicador aislado (muy comÃºn, no sospechoso)                  |
| 2           | 2,621    | 26.5% | Dos coincidencias (frecuente, vigilar si son cuotas + resultado) |
| 3           | 604      | 6.1%  | Tres anomalÃ­as juntas â†’ empieza a ser estadÃ­sticamente raro      |
| 4           | 62       | 0.6%  | Cuatro anomalÃ­as â†’ muy inusual                                   |
| 5           | 5        | 0.1%  | Cinco anomalÃ­as â†’ extremadamente raro                            |

El umbral de 3+ flags se eligiÃ³ porque marca el punto donde la probabilidad de que sea coincidencia empieza a ser baja (solo 6.8% de los partidos).

---

## 7. Etiquetas sintÃ©ticas (is_suspicious) â€” Por quÃ© hay 3 criterios y no solo total_flags

### La pregunta del usuario

> "Si cumple al menos una condiciÃ³n, pero las condiciones 2 y 3 ya no estaban consideradas como un flag... el total de flags ya estÃ¡ medido en el punto 1."

### Respuesta

Correcto: los **flags** (secciÃ³n 4) y las **etiquetas sintÃ©ticas** (secciÃ³n 5) son cosas diferentes que se calculan en momentos distintos del pipeline.

**Los 7 flags** se calculan en `processing/data_cleaning.py` durante el feature engineering. Son variables que alimentan al modelo.

**Las etiquetas sintÃ©ticas** se calculan DESPUÃ‰S, en `models/integrity_scorer.py` (funciÃ³n `create_synthetic_labels`, lÃ­nea 87). Son la variable objetivo (y) para entrenar los modelos supervisados (Random Forest y Logistic Regression).

### Los 3 criterios para etiquetar como sospechoso

```
Criterio 1: total_flags >= 3
            â†’ Usa los flags ya calculados. Captura partidos con MUCHAS seÃ±ales simultÃ¡neas.

Criterio 2: odds_movement_abs_max > percentil 95
            â†’ NO es un flag. Es el valor CONTINUO del movimiento de cuotas.
            El flag_odds_movement se activa con >15%, pero el criterio 2 toma solo el
            top 5% mÃ¡s extremo (que puede ser >40-50%).
            Un partido puede tener flag_odds_movement = 1 (movimiento del 16%)
            pero NO activar el criterio 2 (porque el percentil 95 estÃ¡ en ~35%).

Criterio 3: |Z-Score de goles totales| > 2.5
            â†’ NO es un flag. Es un cÃ¡lculo estadÃ­stico diferente.
            Los flags de goles (4 y 5) comparan goles de UN equipo vs SU promedio.
            El criterio 3 compara TOTAL de goles del partido vs la MEDIA GLOBAL.
            Ejemplo: un partido 4-4 puede no activar ningÃºn flag de goles individuales
            (si ambos equipos son goleadores) pero sÃ­ el criterio 3 (8 goles totales
            es Z > 2.5 cuando la media global es ~2.7 goles).
```

### Resumen de la diferencia

| Concepto                         | DÃ³nde se calcula          | QuÃ© hace                             | RelaciÃ³n                       |
| -------------------------------- | ------------------------- | ------------------------------------ | ------------------------------ |
| Los 7 flags                      | `data_cleaning.py:138`    | Features binarias del modelo         | INPUT del modelo               |
| total_flags                      | `data_cleaning.py:173`    | Suma de flags, tambiÃ©n feature       | INPUT del modelo               |
| Etiqueta is_suspicious           | `integrity_scorer.py:87`  | Variable objetivo para entrenamiento | OUTPUT target                  |
| Criterio 1 (flags>=3)            | `integrity_scorer.py:91`  | Parte de la etiqueta                 | Usa flags como input           |
| Criterio 2 (percentil 95 cuotas) | `integrity_scorer.py:99`  | Parte de la etiqueta                 | Usa valor continuo, NO el flag |
| Criterio 3 (Z-Score goles)       | `integrity_scorer.py:106` | Parte de la etiqueta                 | CÃ¡lculo nuevo, NO es un flag   |

Los criterios 2 y 3 agregan informaciÃ³n **adicional** que los flags solos no capturan: valores extremos continuos que van mÃ¡s allÃ¡ de los umbrales binarios.

---

## 8. Â¿QuÃ© es un Ã¡rbol de decisiÃ³n? (y cÃ³mo lo usa Isolation Forest)

### Ãrbol de decisiÃ³n â€” Concepto

Un Ã¡rbol de decisiÃ³n es un algoritmo que toma decisiones dividiendo los datos paso a paso, como un diagrama de flujo. En cada paso, elige UNA variable y UN umbral para separar los datos en dos grupos.

### Ejemplo visual

Supongamos que queremos clasificar si un partido es sospechoso usando solo 2 variables:

```
                    Â¿odds_movement > 0.20?
                     /                \
                   SÃ                  NO
                  /                      \
        Â¿total_goals > 5?          Â¿total_flags >= 4?
         /          \                /           \
        SÃ          NO             SÃ            NO
        |            |              |              |
   SOSPECHOSO    REVISAR      SOSPECHOSO       NORMAL
```

El Ã¡rbol hace preguntas binarias (sÃ­/no) sobre las variables y va "bajando" hasta llegar a una conclusiÃ³n. Cada "pregunta" se llama un **nodo** y cada conclusiÃ³n final se llama una **hoja**.

### Â¿CÃ³mo usa Isolation Forest los Ã¡rboles?

Isolation Forest usa una idea diferente al Ã¡rbol de clasificaciÃ³n normal. Su lÃ³gica es:

1. **Construye 200 Ã¡rboles** (n_estimators=200), cada uno con divisiones ALEATORIAS
2. Para cada partido, mide **cuÃ¡ntas divisiones necesita para aislarlo** (dejarlo solo en una hoja)
3. Un partido NORMAL estÃ¡ rodeado de muchos partidos similares â†’ necesita MUCHAS divisiones para aislarlo â†’ score bajo
4. Un partido ANÃ“MALO es diferente a todos â†’ se aÃ­sla con MUY POCAS divisiones â†’ score alto

### AnalogÃ­a

Imagina una sala con 100 personas. Si quieres aislar a una persona "normal" (estatura media, ropa comÃºn), necesitas muchas preguntas: "Â¿Mide mÃ¡s de 1.75?", "Â¿Lleva camiseta roja?", "Â¿Tiene barba?"... porque hay muchas personas parecidas.

Pero si hay una persona disfrazada de astronauta, con una sola pregunta ("Â¿Lleva casco?") ya la aislaste. Esa persona es la anomalÃ­a â€” es fÃ¡cil de separar del resto.

Isolation Forest hace exactamente esto con partidos de fÃºtbol: los partidos con combinaciones raras de estadÃ­sticas se "aÃ­slan" rÃ¡pidamente.

---

## 9. Â¿CÃ³mo se sabe que Random Forest es el modelo de mejor rendimiento?

### La mÃ©trica: AUC-ROC

Para comparar modelos de clasificaciÃ³n se usa la mÃ©trica **AUC-ROC** (Area Under the Receiver Operating Characteristic Curve). Esta mÃ©trica mide quÃ© tan bien el modelo distingue entre partidos normales y sospechosos.

| Valor AUC | Significado                                       |
| --------- | ------------------------------------------------- |
| 0.50      | El modelo es igual que lanzar una moneda (inÃºtil) |
| 0.70      | Aceptable                                         |
| 0.80      | Bueno                                             |
| 0.90      | Muy bueno                                         |
| 0.95      | Excelente                                         |
| 1.00      | Perfecto (clasifica todo correctamente)           |

### Resultados obtenidos

| Modelo              | AUC-ROC   | InterpretaciÃ³n                                   |
| ------------------- | --------- | ------------------------------------------------ |
| Isolation Forest    | â€”         | No aplica (no supervisado, no usa etiquetas)     |
| **Random Forest**   | **0.999** | Casi perfecto distinguiendo normal vs sospechoso |
| Logistic Regression | 0.988     | Excelente, pero ligeramente inferior             |

### Â¿CÃ³mo se midiÃ³?

En `models/integrity_scorer.py`, lÃ­neas 129-146:

1. Se separaron los datos: **80% para entrenamiento** y **20% para test** (estratificado para mantener la proporciÃ³n de clases)
2. Se entrenÃ³ cada modelo con el 80%
3. Se evaluÃ³ cada modelo prediciendo el 20% que NUNCA vio durante el entrenamiento
4. Se comparÃ³ la predicciÃ³n con la etiqueta real usando `roc_auc_score` de scikit-learn

### Â¿Por quÃ© 0.999 es tan alto?

El AUC de 0.999 es extremadamente alto. Esto se debe a que las etiquetas sintÃ©ticas fueron creadas a partir de reglas sobre las mismas features que el modelo recibe. No es un "truco" â€” es la consecuencia lÃ³gica del diseÃ±o:

- Las etiquetas dicen "sospechoso si odds_movement > percentil 95"
- El modelo recibe odds_movement como feature
- Naturalmente, el modelo aprende esa relaciÃ³n con precisiÃ³n

Esto **no invalida el modelo**. El valor del modelo estÃ¡ en que:

1. Aprende la **interacciÃ³n** entre variables (ej: cuotas altas + goles anÃ³malos juntos son peor que cada uno por separado)
2. Genera un **score continuo** (0-100), no solo binario (sÃ­/no)
3. Puede aplicarse a **datos nuevos** que no se usaron para crear las etiquetas

### CÃ³digo exacto donde se compara

```python
rf_auc = roc_auc_score(y_test, rf_proba)   # lÃ­nea 137
lr_auc = roc_auc_score(y_test, lr_proba)   # lÃ­nea 145
```

Random Forest gana: 0.999 > 0.988. Por eso recibe el mayor peso (40%) en el ensamble.

---

## 10. ExplicaciÃ³n funcional de cada modelo y su configuraciÃ³n

### 10.1 Isolation Forest â€” ConfiguraciÃ³n y parÃ¡metros

CÃ³digo: `models/integrity_scorer.py`, lÃ­neas 55-60

```python
IsolationForest(
    contamination=0.08,
    n_estimators=200,
    max_samples="auto",
    random_state=42,
)
```

| ParÃ¡metro       | Valor  | QuÃ© significa                                                                                                                                          |
| --------------- | ------ | ------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `contamination` | 0.08   | Le dice al modelo que asuma que el 8% de los datos son anomalÃ­as. Se eligiÃ³ 8% porque es cercano al porcentaje de partidos con total_flags >= 3 (6.8%) |
| `n_estimators`  | 200    | Usa 200 Ã¡rboles aleatorios. MÃ¡s Ã¡rboles = resultado mÃ¡s estable. 200 es un buen balance entre precisiÃ³n y velocidad                                    |
| `max_samples`   | "auto" | Cada Ã¡rbol se entrena con un subconjunto aleatorio de los datos (por defecto 256 muestras o el total si hay menos)                                     |
| `random_state`  | 42     | Semilla de aleatoriedad para reproducibilidad. Siempre da el mismo resultado si se ejecuta de nuevo                                                    |

**Proceso funcional**:

1. Recibe las 12 features escaladas (StandardScaler)
2. Construye 200 Ã¡rboles con divisiones aleatorias
3. Para cada partido calcula un "anomaly score" basado en la profundidad promedio de aislamiento
4. `decision_function()` devuelve un score continuo (mÃ¡s negativo = mÃ¡s anÃ³malo)
5. Se normaliza a 0-1 y se invierte (1 = mÃ¡s anÃ³malo)

### 10.2 Random Forest Classifier â€” ConfiguraciÃ³n y parÃ¡metros

CÃ³digo: `models/integrity_scorer.py`, lÃ­neas 61-67

```python
RandomForestClassifier(
    n_estimators=200,
    max_depth=10,
    min_samples_leaf=5,
    random_state=42,
    class_weight="balanced",
)
```

| ParÃ¡metro          | Valor      | QuÃ© significa                                                                                                                                                         |
| ------------------ | ---------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `n_estimators`     | 200        | 200 Ã¡rboles de decisiÃ³n votan. La clase con mÃ¡s votos gana                                                                                                            |
| `max_depth`        | 10         | Cada Ã¡rbol puede tener mÃ¡ximo 10 niveles de profundidad. Limita la complejidad para evitar overfitting (que el modelo memorice los datos en vez de aprender patrones) |
| `min_samples_leaf` | 5          | Cada hoja final debe tener al menos 5 partidos. Evita que el modelo cree reglas basadas en 1 solo partido                                                             |
| `class_weight`     | "balanced" | AutomÃ¡ticamente da mÃ¡s importancia a la clase minoritaria (sospechoso, 11.5%) para compensar que hay muchos mÃ¡s partidos normales (88.5%)                             |
| `random_state`     | 42         | Reproducibilidad                                                                                                                                                      |

**Proceso funcional**:

1. Recibe las 12 features escaladas + las etiquetas sintÃ©ticas (0 = normal, 1 = sospechoso)
2. Separa 80% entrenamiento, 20% test
3. Construye 200 Ã¡rboles, cada uno entrenado con un subconjunto aleatorio de datos y features
4. Para un partido nuevo, los 200 Ã¡rboles "votan" â†’ `predict_proba()` da la proporciÃ³n de Ã¡rboles que votaron "sospechoso"
5. Si 180 de 200 Ã¡rboles dicen "sospechoso" â†’ probabilidad = 0.90 (90%)

### 10.3 Logistic Regression â€” ConfiguraciÃ³n y parÃ¡metros

CÃ³digo: `models/integrity_scorer.py`, lÃ­neas 68-72

```python
LogisticRegression(
    max_iter=1000,
    class_weight="balanced",
    random_state=42,
)
```

| ParÃ¡metro      | Valor      | QuÃ© significa                                                                                      |
| -------------- | ---------- | -------------------------------------------------------------------------------------------------- |
| `max_iter`     | 1000       | MÃ¡ximo 1000 iteraciones para converger. El algoritmo busca los coeficientes Ã³ptimos iterativamente |
| `class_weight` | "balanced" | Compensa el desbalance de clases (igual que Random Forest)                                         |
| `random_state` | 42         | Reproducibilidad                                                                                   |

**Proceso funcional**:

1. Aprende una ecuaciÃ³n lineal: `P(sospechoso) = sigmoid(Î²â‚€ + Î²â‚Ã—feature_1 + Î²â‚‚Ã—feature_2 + ... + Î²â‚â‚‚Ã—feature_12)`
2. La funciÃ³n sigmoid convierte cualquier nÃºmero a un rango entre 0 y 1 (probabilidad)
3. Cada coeficiente Î² indica: si es positivo â†’ esa feature aumenta la sospecha; si es negativo â†’ la disminuye
4. Es el modelo mÃ¡s simple e interpretable de los 3

### 10.4 Escalado de datos (StandardScaler)

Antes de entrar a cualquier modelo, todas las features se escalan:

```python
X_scaled = scaler.fit_transform(X)  # lÃ­nea 120
```

Esto transforma cada feature para que tenga media = 0 y desviaciÃ³n estÃ¡ndar = 1. Es necesario porque:

- `odds_movement_abs_max` va de 0 a 2.0
- `total_goals` va de 0 a 12
- `flag_streak_break` es 0 o 1

Sin escalar, las variables con rangos mÃ¡s grandes dominarÃ­an a las pequeÃ±as.

---

## 11. Â¿CÃ³mo se determinaron los pesos del ensamble (35%, 40%, 25%)?

### La fÃ³rmula del ensamble

```python
combined = (0.35 * iso_norm + 0.40 * rf_proba + 0.25 * lr_proba)  # lÃ­nea 173
```

CÃ³digo: `models/integrity_scorer.py`, lÃ­nea 173

### Criterios para asignar los pesos

Los pesos se asignaron siguiendo 3 principios:

**Principio 1: El modelo con mejor rendimiento medible recibe mÃ¡s peso**

- Random Forest tiene AUC 0.999 â†’ recibe el mayor peso: **40%**
- Logistic Regression tiene AUC 0.988 â†’ recibe menos: **25%**
- Isolation Forest no tiene AUC medible (no supervisado) â†’ peso intermedio

**Principio 2: Diversidad de enfoques**

- Si solo usÃ¡ramos Random Forest (100%), el score dependerÃ­a completamente de las etiquetas sintÃ©ticas. Si las etiquetas tienen errores, el score hereda todos esos errores.
- Isolation Forest NO usa etiquetas â†’ su perspectiva es independiente y aporta diversidad. Por eso recibe **35%** a pesar de no tener AUC medible.
- Tener modelos diversos es una prÃ¡ctica estÃ¡ndar en ML llamada "ensemble learning".

**Principio 3: Estabilidad y regularizaciÃ³n**

- Logistic Regression es un modelo lineal simple que no se "sobreajusta" a los datos. Funciona como un contrapeso estabilizador.
- Si Random Forest y Isolation Forest dan scores altos pero Logistic Regression da score bajo, el score final se modera. Esto reduce falsos positivos.

### Â¿Son los pesos Ã³ptimos?

No necesariamente. Se podrÃ­an optimizar los pesos usando validaciÃ³n cruzada o un meta-aprendizaje (stacking). Los pesos actuales (35/40/25) son una asignaciÃ³n razonable basada en el rendimiento observado, la diversidad de los modelos y las buenas prÃ¡cticas de ensemble. Es una decisiÃ³n de diseÃ±o, no un resultado matemÃ¡tico exacto.

Una alternativa serÃ­a usar un modelo de "stacking" donde un cuarto modelo aprende los pesos Ã³ptimos automÃ¡ticamente. Esto se podrÃ­a implementar como mejora futura.

---

## 12. Los 7 flags de anomalÃ­a â€” Criterios y ubicaciÃ³n en el cÃ³digo

### Resumen visual

```
processing/data_cleaning.py â†’ flag_anomalies() [lÃ­nea 138]
â”œâ”€â”€ flag_odds_movement .......... lÃ­nea 142  â”‚ Â¿Cuotas se movieron >15%?
â”œâ”€â”€ flag_result_surprise ........ lÃ­nea 145  â”‚ Â¿Resultado diferente al esperado?
â”œâ”€â”€ flag_streak_break ........... lÃ­nea 148  â”‚ Â¿Racha de 5+ victorias rota en casa?
â”œâ”€â”€ flag_goals_anomaly_home ..... lÃ­nea 153  â”‚ Â¿Local marcÃ³ >4Ã— su promedio?
â”œâ”€â”€ flag_goals_anomaly_away ..... lÃ­nea 156  â”‚ Â¿Visitante marcÃ³ >4Ã— su promedio?
â”œâ”€â”€ flag_ht_result_changed ...... lÃ­nea 161  â”‚ Â¿CambiÃ³ el resultado entre tiempos?
â”œâ”€â”€ flag_cards_anomaly .......... lÃ­nea 164  â”‚ Â¿Tarjetas con Z-Score >2?
â””â”€â”€ total_flags ................. lÃ­nea 173  â”‚ Suma de todos los anteriores
```

---

## 13. Niveles de alerta â€” Umbrales y significado

Definidos en `config/settings.py`, lÃ­neas 33-38:

```python
MATCH_INTEGRITY_THRESHOLDS = {
    "normal": (0, 30),
    "monitor": (31, 60),
    "suspicious": (61, 80),
    "high_alert": (81, 100),
}
```

Aplicados en `models/integrity_scorer.py`, lÃ­neas 177-181:

```python
alert_levels = pd.cut(
    integrity_score,
    bins=[-1, 30, 60, 80, 101],
    labels=["normal", "monitor", "suspicious", "high_alert"],
)
```

| Nivel         | Rango MIS | QuÃ© significa en la prÃ¡ctica                                                                                                                                                                                                                                   | Cantidad | %     |
| ------------- | --------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------- | ----- |
| ğŸŸ¢ Normal     | 0 â€” 30    | Los 3 modelos coinciden en que el partido no presenta anomalÃ­as significativas. Las cuotas se mantuvieron estables, el resultado fue esperado, los goles y tarjetas estÃ¡n dentro de lo normal.                                                                 | 7,820    | 79.2% |
| ğŸŸ¡ Monitor    | 31 â€” 60   | Al menos uno de los 3 modelos detecta algo inusual, pero no hay consenso. Puede ser un movimiento de cuotas moderado o un resultado ligeramente sorpresivo. RecomendaciÃ³n: anotar y revisar si se repite con el mismo equipo.                                  | 902      | 9.1%  |
| ğŸŸ  Suspicious | 61 â€” 80   | Al menos 2 de los 3 modelos seÃ±alan anomalÃ­as. TÃ­picamente: cuotas se movieron bastante (>20%) + resultado sorpresa + algÃºn flag adicional. RecomendaciÃ³n: investigar el partido, revisar noticias, verificar si hubo lesiones o factores externos.            | 642      | 6.5%  |
| ğŸ”´ High Alert | 81 â€” 100  | Los 3 modelos coinciden en que el partido es altamente anÃ³malo. CombinaciÃ³n extrema: cuotas se movieron >30%, resultado totalmente inesperado, goles muy por encima del promedio, cambio de resultado entre tiempos. RecomendaciÃ³n: investigaciÃ³n prioritaria. | 509      | 5.2%  |

---

## 14. Limitaciones y consideraciones

1. **No hay "ground truth"**: las etiquetas son sintÃ©ticas. El modelo detecta anomalÃ­as estadÃ­sticas, NO prueba amaÃ±os.
2. **Falsos positivos**: un partido con score alto puede tener explicaciones legÃ­timas (lesiones de Ãºltimo momento, condiciones climÃ¡ticas, motivaciÃ³n del equipo).
3. **El movimiento de cuotas domina**: el 63% de la importancia recae en cuotas. Si las cuotas no estÃ¡n disponibles (ej: datos de Europa League vÃ­a ESPN), el modelo pierde poder predictivo.
4. **Sesgo temporal**: los patrones de apuestas cambian con el tiempo. El modelo debe reentrenarse periÃ³dicamente.
5. **CorrelaciÃ³n â‰  causalidad**: un score alto es una seÃ±al para investigar, no una acusaciÃ³n.

---

## 15. CÃ³mo interpretar el dashboard

- **Tab "AnÃ¡lisis General"**: visiÃ³n macro. Si una liga tiene muchos partidos en zona roja, merece atenciÃ³n.
- **Tab "Alertas"**: lista priorizada de partidos sospechosos. Empezar investigaciÃ³n por los de score mÃ¡s alto.
- **Tab "Europa League"**: datos especÃ­ficos de la competiciÃ³n UEFA.
- **Tab "Datos completos"**: tabla filtrable para explorar cualquier partido. Usar filtro de liga + ordenar por score.

El sistema estÃ¡ diseÃ±ado para ser una **primera barrera** â€” no reemplaza la investigaciÃ³n humana, pero la prioriza y la hace mÃ¡s eficiente.

---

## 16. Estructura del proyecto â€” Archivos y carpetas

```
fair_play_shield/
â”‚
â”œâ”€â”€ main.py                              # Punto de entrada principal del pipeline
â”œâ”€â”€ requirements.txt                     # Dependencias Python
â”œâ”€â”€ README.md                            # DocumentaciÃ³n bÃ¡sica
â”œâ”€â”€ TECHNICAL_README.md                  # Esta guÃ­a tÃ©cnica completa
â”œâ”€â”€ .env.example                         # Plantilla de variables de entorno
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py                      # ConfiguraciÃ³n global (umbrales, rutas, URLs)
â”‚
â”œâ”€â”€ database/
â”‚   â””â”€â”€ schema.sql                       # Esquema PostgreSQL para producciÃ³n
â”‚
â”œâ”€â”€ ingestion/
â”‚   â””â”€â”€ scrapers/
â”‚       â”œâ”€â”€ european_leagues_scraper.py  # Descarga 10 ligas europeas (football-data.co.uk)
â”‚       â””â”€â”€ europa_league_scraper.py     # Descarga Europa League (ESPN API)
â”‚
â”œâ”€â”€ processing/
â”‚   â””â”€â”€ data_cleaning.py                 # Limpieza + feature engineering + flags
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ integrity_scorer.py              # Entrenamiento de los 3 modelos + scoring
â”‚   â””â”€â”€ trained/                         # Modelos serializados (.pkl)
â”‚       â”œâ”€â”€ fps_leagues_scaler.pkl
â”‚       â”œâ”€â”€ fps_leagues_isolation_forest.pkl
â”‚       â”œâ”€â”€ fps_leagues_random_forest.pkl
â”‚       â”œâ”€â”€ fps_leagues_logistic.pkl
â”‚       â””â”€â”€ fps_leagues_feature_cols.pkl
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 01_eda.py                        # AnÃ¡lisis exploratorio + tests estadÃ­sticos
â”‚
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ app.py                           # Dashboard Dash/Plotly (http://localhost:8050)
â”‚
â”œâ”€â”€ alerts/
â”‚   â””â”€â”€ __init__.py                      # MÃ³dulo de alertas (extensible)
â”‚
â””â”€â”€ data/
    â”œâ”€â”€ raw/                             # Datos descargados sin procesar
    â”‚   â”œâ”€â”€ european_leagues_with_odds.csv
    â”‚   â””â”€â”€ europa_league_matches.csv
    â”œâ”€â”€ processed/                       # Datos procesados + scores
    â”‚   â”œâ”€â”€ european_leagues_with_odds_processed.csv
    â”‚   â”œâ”€â”€ europa_league_processed.csv
    â”‚   â””â”€â”€ integrity_scores.csv         # â† Archivo final con MIS
    â””â”€â”€ eda_output/                       # GrÃ¡ficos generados por EDA
```

---

## 17. Flujo completo del sistema â€” Diagrama

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           FASE 1: INGESTA                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  football-data.co.uk â”€â”€â”€â”€â”€â”€â”                                                â”‚
â”‚  (CSVs con cuotas)         â”‚                                                â”‚
â”‚                            â–¼                                                â”‚
â”‚              european_leagues_scraper.py                                    â”‚
â”‚                            â”‚                                                â”‚
â”‚                            â–¼                                                â”‚
â”‚              data/raw/european_leagues_with_odds.csv                        â”‚
â”‚              (9,873 partidos Ã— 100+ columnas)                               â”‚
â”‚                                                                             â”‚
â”‚  ESPN API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                â”‚
â”‚  (JSON partidos)           â”‚                                                â”‚
â”‚                            â–¼                                                â”‚
â”‚              europa_league_scraper.py                                       â”‚
â”‚                            â”‚                                                â”‚
â”‚                            â–¼                                                â”‚
â”‚              data/raw/europa_league_matches.csv                             â”‚
â”‚              (471 partidos Ã— 30+ columnas)                                  â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FASE 2: FEATURE ENGINEERING                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚              processing/data_cleaning.py                                    â”‚
â”‚                            â”‚                                                â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚              â–¼             â–¼             â–¼                                  â”‚
â”‚         clean_matches  compute_team_form  flag_anomalies                    â”‚
â”‚              â”‚             â”‚             â”‚                                  â”‚
â”‚              â”‚             â”‚             â”œâ”€â”€ flag_odds_movement             â”‚
â”‚              â”‚             â”‚             â”œâ”€â”€ flag_result_surprise           â”‚
â”‚              â”‚             â”‚             â”œâ”€â”€ flag_streak_break              â”‚
â”‚              â”‚             â”‚             â”œâ”€â”€ flag_goals_anomaly_home        â”‚
â”‚              â”‚             â”‚             â”œâ”€â”€ flag_goals_anomaly_away        â”‚
â”‚              â”‚             â”‚             â”œâ”€â”€ flag_ht_result_changed         â”‚
â”‚              â”‚             â”‚             â”œâ”€â”€ flag_cards_anomaly             â”‚
â”‚              â”‚             â”‚             â””â”€â”€ total_flags                    â”‚
â”‚              â”‚             â”‚             â”‚                                  â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚                            â”‚                                                â”‚
â”‚                            â–¼                                                â”‚
â”‚              data/processed/european_leagues_with_odds_processed.csv        â”‚
â”‚              (9,873 partidos Ã— 120+ columnas incluyendo flags)              â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        FASE 3: MODELADO ML                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚              models/integrity_scorer.py                                     â”‚
â”‚                            â”‚                                                â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚              â–¼             â–¼             â–¼                                  â”‚
â”‚       Isolation Forest  Random Forest  Logistic Regression                 â”‚
â”‚       (no supervisado)  (supervisado)  (supervisado)                        â”‚
â”‚              â”‚             â”‚             â”‚                                  â”‚
â”‚              â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”      â”‚                                  â”‚
â”‚              â”‚      â–¼             â–¼      â”‚                                  â”‚
â”‚              â”‚   80% train    20% test   â”‚                                  â”‚
â”‚              â”‚      â”‚             â”‚      â”‚                                  â”‚
â”‚              â”‚      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â”‚                                  â”‚
â”‚              â”‚             â”‚             â”‚                                  â”‚
â”‚              â–¼             â–¼             â–¼                                  â”‚
â”‚         iso_score      rf_proba      lr_proba                               â”‚
â”‚           (0-1)         (0-1)         (0-1)                                 â”‚
â”‚              â”‚             â”‚             â”‚                                  â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚                            â”‚                                                â”‚
â”‚                            â–¼                                                â”‚
â”‚              MIS = 0.35Ã—iso + 0.40Ã—rf + 0.25Ã—lr                             â”‚
â”‚                            â”‚                                                â”‚
â”‚                            â–¼                                                â”‚
â”‚              Match Integrity Score (0-100)                                  â”‚
â”‚                            â”‚                                                â”‚
â”‚                            â–¼                                                â”‚
â”‚              Alert Level: normal / monitor / suspicious / high_alert        â”‚
â”‚                            â”‚                                                â”‚
â”‚                            â–¼                                                â”‚
â”‚              data/processed/integrity_scores.csv                            â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        FASE 4: VISUALIZACIÃ“N                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚              dashboard/app.py                                               â”‚
â”‚                            â”‚                                                â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚              â–¼             â–¼             â–¼             â–¼                    â”‚
â”‚         Tab 1          Tab 2         Tab 3         Tab 4                    â”‚
â”‚      AnÃ¡lisis       Alertas      Europa League   Datos                      â”‚
â”‚       General     (filtrable)    (stats EL)    Completos                    â”‚
â”‚                                                                             â”‚
â”‚              Servidor local: http://localhost:8050                          â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 18. AclaraciÃ³n importante: Â¿Se usa el mismo dataset para entrenar y predecir?

### Respuesta corta: SÃ­, actualmente sÃ­.

### Flujo actual (limitaciÃ³n conocida)

```
european_leagues_with_odds_processed.csv (9,873 partidos)
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  integrity_scorer.py                  â”‚
â”‚  - Entrena con 80% de los datos       â”‚
â”‚  - EvalÃºa mÃ©tricas con 20% (test)     â”‚
â”‚  - PERO luego aplica score() a TODO   â”‚
â”‚    el dataset (100%)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
integrity_scores.csv (9,873 partidos con MIS)
        â”‚
        â–¼
dashboard/app.py (muestra los 9,873 partidos)
```

### Â¿Es esto un problema?

**Para un sistema de producciÃ³n, sÃ­ serÃ­a un problema** â€” estarÃ­as mostrando predicciones sobre datos que el modelo ya "vio" durante el entrenamiento, lo cual infla artificialmente la confianza.

**Para este proyecto acadÃ©mico/demo, es aceptable** porque:

1. El objetivo es demostrar el concepto, no desplegar en producciÃ³n
2. El modelo se evaluÃ³ correctamente con un split 80/20 estratificado (AUC 0.999 es sobre el 20% que NO se usÃ³ para entrenar)
3. Los scores del dashboard son ilustrativos, no decisiones finales

### Â¿CÃ³mo serÃ­a en producciÃ³n?

```
Datos histÃ³ricos (temporadas pasadas) â†’ Entrenar modelo una vez
Datos nuevos (partidos de esta semana) â†’ Aplicar modelo entrenado â†’ Dashboard
```

El modelo nunca verÃ­a los partidos nuevos hasta que ya estÃ¡ entrenado. Esto se implementarÃ­a separando el pipeline en:

1. `train_model.py` â€” se ejecuta una vez con datos histÃ³ricos
2. `score_new_matches.py` â€” se ejecuta cada semana con partidos nuevos

---

## 19. Los 7 flags â€” FÃ³rmulas matemÃ¡ticas exactas y ejemplos

### Flag 1: `flag_odds_movement`

**Archivo**: `processing/data_cleaning.py`, lÃ­nea 142

**FÃ³rmula**:

```
odds_movement_X = (ps_close_X - ps_X) / ps_X    para X âˆˆ {home, draw, away}

odds_movement_abs_max = max(|odds_movement_home|, |odds_movement_draw|, |odds_movement_away|)

flag_odds_movement = 1 si odds_movement_abs_max > 0.15, sino 0
```

**Ejemplo numÃ©rico**:

- Cuota apertura local (ps_home): 2.10
- Cuota cierre local (ps_close_home): 1.75
- Movimiento: (1.75 - 2.10) / 2.10 = **-0.167 = -16.7%**
- |âˆ’16.7%| = 16.7% > 15% â†’ **flag = 1**

---

### Flag 2: `flag_result_surprise`

**Archivo**: `ingestion/scrapers/european_leagues_scraper.py`, lÃ­nea 181

**FÃ³rmula**:

```
implied_prob_X = 1 / avg_odds_X                 para X âˆˆ {home, draw, away}

prob_sum = implied_prob_home + implied_prob_draw + implied_prob_away

norm_prob_X = implied_prob_X / prob_sum         (normalizaciÃ³n)

expected_result = argmax(norm_prob_home, norm_prob_draw, norm_prob_away)

flag_result_surprise = 1 si result â‰  expected_result, sino 0
```

**Ejemplo numÃ©rico**:

- Cuotas promedio: Home=1.80, Draw=3.50, Away=4.50
- Prob implÃ­cita: Home=1/1.80=0.556, Draw=1/3.50=0.286, Away=1/4.50=0.222
- Suma: 0.556 + 0.286 + 0.222 = 1.064
- Prob normalizada: Home=0.522, Draw=0.269, Away=0.209
- Resultado esperado: **H** (local, mayor probabilidad)
- Resultado real: **A** (visitante ganÃ³)
- H â‰  A â†’ **flag = 1**

---

### Flag 3: `flag_streak_break`

**Archivo**: `processing/data_cleaning.py`, lÃ­neas 147-150

**FÃ³rmula**:

```
home_win_streak = nÃºmero de victorias consecutivas del equipo local ANTES de este partido

flag_streak_break = 1 si (home_win_streak >= 5 AND result == "A"), sino 0
```

**Ejemplo**:

- Equipo local: Ãºltimos 5 resultados = W, W, W, W, W â†’ racha = 5
- Resultado de este partido: A (pierde en casa)
- 5 >= 5 AND result == "A" â†’ **flag = 1**

---

### Flag 4: `flag_goals_anomaly_home`

**Archivo**: `processing/data_cleaning.py`, lÃ­neas 152-155

**FÃ³rmula**:

```
home_avg_goals_scored = Î£(goles_marcados_local) / total_partidos_jugados

flag_goals_anomaly_home = 1 si home_goals > home_avg_goals_scored Ã— 4, sino 0
```

**Ejemplo**:

- Equipo local ha marcado 18 goles en 15 partidos â†’ promedio = 1.2
- En este partido marca 5 goles
- 5 > 1.2 Ã— 4 = 4.8 â†’ **flag = 1**

---

### Flag 5: `flag_goals_anomaly_away`

**Archivo**: `processing/data_cleaning.py`, lÃ­neas 156-158

**FÃ³rmula**: IdÃ©ntica al flag 4, pero para el equipo visitante.

---

### Flag 6: `flag_ht_result_changed`

**Archivo**: `processing/data_cleaning.py`, lÃ­nea 161

**FÃ³rmula**:

```
ht_result = "H" si ht_home_goals > ht_away_goals
            "A" si ht_home_goals < ht_away_goals
            "D" si ht_home_goals == ht_away_goals

flag_ht_result_changed = 1 si ht_result â‰  result, sino 0
```

**Ejemplo**:

- Medio tiempo: 1-0 â†’ ht_result = "H"
- Final: 1-2 â†’ result = "A"
- "H" â‰  "A" â†’ **flag = 1**

---

### Flag 7: `flag_cards_anomaly`

**Archivo**: `processing/data_cleaning.py`, lÃ­neas 163-169

**FÃ³rmula**:

```
Î¼ = mean(total_cards)           # media de tarjetas en todo el dataset
Ïƒ = std(total_cards)            # desviaciÃ³n estÃ¡ndar

z_score = (total_cards_partido - Î¼) / Ïƒ

flag_cards_anomaly = 1 si z_score > 2, sino 0
```

**Ejemplo**:

- Media de tarjetas en el dataset: Î¼ = 4.2
- DesviaciÃ³n estÃ¡ndar: Ïƒ = 1.8
- Este partido tuvo 9 tarjetas
- Z = (9 - 4.2) / 1.8 = **2.67**
- 2.67 > 2 â†’ **flag = 1**

---

### Variable derivada: `total_flags`

**Archivo**: `processing/data_cleaning.py`, lÃ­nea 173

**FÃ³rmula**:

```
total_flags = flag_odds_movement + flag_result_surprise + flag_streak_break +
              flag_goals_anomaly_home + flag_goals_anomaly_away +
              flag_ht_result_changed + flag_cards_anomaly
```

**Rango**: 0 a 7

---

## 20. JustificaciÃ³n de umbrales â€” Por quÃ© se eligiÃ³ cada valor

| Umbral                      | Valor | JustificaciÃ³n                                                                                                                                                                                             |
| --------------------------- | ----- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Movimiento cuotas >15%**  | 0.15  | Basado en literatura de Sportradar: movimientos >10-15% sin causa conocida son seÃ±al de "smart money". Se eligiÃ³ 15% para reducir falsos positivos (movimientos legÃ­timos por lesiones suelen ser 5-10%). |
| **Racha de 5+ victorias**   | 5     | Una racha de 5+ victorias consecutivas ocurre en ~5% de los equipos. Es estadÃ­sticamente significativa. Perder en casa despuÃ©s de esa racha es inusual (~0.3% de partidos).                               |
| **Goles >4Ã— promedio**      | 4     | Multiplicador de 4 captura outliers extremos. Si un equipo promedia 1.2 goles, marcar 5+ es un evento raro (percentil >99).                                                                               |
| **Z-Score tarjetas >2**     | 2.0   | En una distribuciÃ³n normal, solo ~2.3% de los datos caen fuera de Â±2Ïƒ. Es el umbral estÃ¡ndar para detectar outliers estadÃ­sticos.                                                                         |
| **MIS 0-30 = Normal**       | 30    | ~80% de los partidos caen aquÃ­. Es el comportamiento "normal" del fÃºtbol.                                                                                                                                 |
| **MIS 31-60 = Monitor**     | 60    | ~9% de partidos. Al menos 1 modelo detecta algo, pero no hay consenso.                                                                                                                                    |
| **MIS 61-80 = Suspicious**  | 80    | ~6.5% de partidos. 2+ modelos coinciden en anomalÃ­a.                                                                                                                                                      |
| **MIS 81-100 = High Alert** | 100   | ~5% de partidos. Los 3 modelos coinciden en anomalÃ­a extrema.                                                                                                                                             |

**Nota**: Los cortes del MIS (30/60/80) se eligieron **empÃ­ricamente** observando la distribuciÃ³n del score en los datos y buscando puntos naturales de separaciÃ³n. No son Ã³ptimos matemÃ¡ticos â€” son decisiones de diseÃ±o para que cada categorÃ­a tenga un tamaÃ±o razonable y sea accionable.

---

## 21. Feature Importance â€” QuÃ© variables pesan mÃ¡s en la decisiÃ³n

Calculado por Random Forest (`models/integrity_scorer.py`, lÃ­neas 148-154):

| Feature                   | Importancia | %   | InterpretaciÃ³n                                                                             |
| ------------------------- | ----------- | --- | ------------------------------------------------------------------------------------------ |
| `odds_movement_abs_max`   | 0.4129      | 41% | **El indicador principal**. El valor continuo del movimiento de cuotas domina la decisiÃ³n. |
| `flag_odds_movement`      | 0.2234      | 22% | El flag binario refuerza lo anterior. Juntos suman **63%**.                                |
| `total_goals`             | 0.0752      | 8%  | Partidos con muchos goles son mÃ¡s sospechosos.                                             |
| `flag_goals_anomaly_away` | 0.0510      | 5%  | Goles inesperados del visitante.                                                           |
| `flag_goals_anomaly_home` | 0.0418      | 4%  | Goles inesperados del local.                                                               |
| `total_cards`             | 0.0401      | 4%  | Exceso de tarjetas.                                                                        |
| `ht_result_changed`       | 0.0344      | 3%  | Cambio de resultado entre tiempos.                                                         |
| `flag_ht_result_changed`  | 0.0327      | 3%  | Flag binario del cambio HT.                                                                |
| `flag_cards_anomaly`      | 0.0326      | 3%  | Flag de tarjetas extremas.                                                                 |
| `result_surprise`         | 0.0251      | 3%  | Resultado vs expectativa del mercado.                                                      |
| `flag_result_surprise`    | 0.0249      | 2%  | Flag de sorpresa.                                                                          |
| `flag_streak_break`       | 0.0059      | 1%  | Ruptura de racha (raro pero especÃ­fico).                                                   |

**ConclusiÃ³n clave**: El **63% de la decisiÃ³n** del modelo depende del movimiento de cuotas de apuestas. Esto es consistente con la realidad: el mercado de apuestas es el primer lugar donde se manifiesta un amaÃ±o.

---

## 22. IntegraciÃ³n con Airflow y MLflow

### Arquitectura de orquestaciÃ³n

El proyecto incluye integraciÃ³n con **Apache Airflow** para orquestaciÃ³n de pipelines y **MLflow** para tracking de experimentos ML.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           AIRFLOW (OrquestaciÃ³n)                            â”‚
â”‚                                                                             â”‚
â”‚   DAG: fps_pipeline                                                         â”‚
â”‚   Schedule: Lunes 6:00 AM (@weekly)                                         â”‚
â”‚                                                                             â”‚
â”‚   start â”€â”€â–¶ [ingest_european_leagues] â”€â”€â”                                   â”‚
â”‚             [ingest_europa_league]   â”€â”€â”€â”´â”€â”€â–¶ process_data â”€â”€â–¶ train â”€â”€â–¶ end â”‚
â”‚                                                    â”‚                        â”‚
â”‚                                                    â–¼                        â”‚
â”‚                                               MLflow Tracking               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Servicios Docker

| Servicio              | Puerto | DescripciÃ³n                         |
| --------------------- | ------ | ----------------------------------- |
| **Airflow Webserver** | 8080   | UI para monitorear DAGs y tasks     |
| **Airflow Scheduler** | â€”      | Ejecuta los DAGs programados        |
| **MLflow Server**     | 5001   | UI para tracking de experimentos    |
| **PostgreSQL**        | 5432   | Base de datos para Airflow metadata |

### Archivos de configuraciÃ³n

| Archivo                            | PropÃ³sito                                    |
| ---------------------------------- | -------------------------------------------- |
| `docker-compose.yml`               | DefiniciÃ³n de todos los servicios            |
| `Dockerfile.airflow`               | Imagen custom con dependencias del proyecto  |
| `requirements-airflow.txt`         | Dependencias adicionales (mlflow, providers) |
| `airflow/dags/fps_pipeline_dag.py` | DAG principal del pipeline                   |
| `scripts/init_airflow.sh`          | Script de inicializaciÃ³n                     |

### Iniciar los servicios

```bash
./scripts/init_airflow.sh
```

Esto ejecuta:

1. Crea archivo `.env` con `AIRFLOW_UID`
2. Crea directorios necesarios
3. Construye imÃ¡genes Docker
4. Levanta todos los servicios

### URLs de acceso

- **Airflow UI**: http://localhost:8080 (user: `airflow`, pass: `airflow`)
- **MLflow UI**: http://localhost:5001

### Comandos Ãºtiles

```bash
docker-compose logs -f                    # Ver logs en tiempo real
docker-compose down                       # Detener servicios
docker-compose up -d                      # Reiniciar servicios

docker exec airflow-scheduler airflow dags trigger fps_pipeline   # Ejecutar pipeline manualmente
docker exec airflow-scheduler airflow dags list                   # Listar DAGs
docker exec airflow-scheduler airflow tasks list fps_pipeline     # Listar tasks del DAG
```

### MLflow Tracking â€” QuÃ© se registra

Cada ejecuciÃ³n del pipeline registra en MLflow:

**ParÃ¡metros**:

- `isolation_forest_contamination`: 0.08
- `isolation_forest_n_estimators`: 200
- `random_forest_n_estimators`: 200
- `random_forest_max_depth`: 10
- `ensemble_weight_if/rf/lr`: 0.35, 0.40, 0.25
- `n_features`: nÃºmero de features usadas
- `total_matches`: partidos procesados

**MÃ©tricas**:

- `rf_auc`, `lr_auc`: AUC-ROC de cada modelo
- `rf_precision`, `rf_recall`, `rf_f1`: mÃ©tricas de Random Forest
- `lr_precision`, `lr_recall`, `lr_f1`: mÃ©tricas de Logistic Regression
- `iso_anomalies_pct`: % de anomalÃ­as detectadas por Isolation Forest
- `alert_normal_count/pct`, `alert_monitor_count/pct`, etc.: distribuciÃ³n de alertas
- `avg_integrity_score`, `max_integrity_score`

**Artefactos**:

- Modelos serializados (Isolation Forest, Random Forest, Logistic Regression)
- `feature_importance.csv`: importancia de cada feature

### DAG Tasks â€” Detalle

| Task                      | FunciÃ³n                        | Archivo fuente                                   |
| ------------------------- | ------------------------------ | ------------------------------------------------ |
| `ingest_european_leagues` | Descarga 10 ligas europeas     | `ingestion/scrapers/european_leagues_scraper.py` |
| `ingest_europa_league`    | Descarga Europa League         | `ingestion/scrapers/europa_league_scraper.py`    |
| `process_data`            | Limpieza + feature engineering | `processing/data_cleaning.py`                    |
| `train_and_score`         | Entrena modelos + genera MIS   | `models/integrity_scorer.py`                     |
| `notify_completion`       | Imprime resumen final          | Inline en DAG                                    |

### EjecuciÃ³n sin Docker (desarrollo local)

Si prefieres ejecutar sin Docker:

```bash
pip install mlflow apache-airflow

export MLFLOW_TRACKING_URI=http://localhost:5001

mlflow server --host 0.0.0.0 --port 5001 &

python models/integrity_scorer.py
```

El cÃ³digo detecta automÃ¡ticamente si MLflow estÃ¡ disponible y logea si la conexiÃ³n es exitosa.

---

## 23. Deployment en AWS (Free Tier)

### Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AWS FREE TIER ($0/mes)                      â”‚
â”‚                                                                â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚              EC2 t2.micro (1 instancia)              â”‚     â”‚
â”‚   â”‚                                                      â”‚     â”‚
â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚     â”‚
â”‚   â”‚   â”‚ Dashboardâ”‚  â”‚  MLflow  â”‚  â”‚ Airflow  â”‚          â”‚     â”‚
â”‚   â”‚   â”‚  (8050)  â”‚  â”‚  (5001)  â”‚  â”‚  (8080)  â”‚          â”‚     â”‚
â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                          â”‚                                     â”‚
â”‚                          â–¼                                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚ RDS t2.micro â”‚    â”‚     S3       â”‚    â”‚ EventBridge  â”‚    â”‚
â”‚   â”‚  PostgreSQL  â”‚    â”‚ data/models  â”‚    â”‚  + Lambda    â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes AWS

| Servicio        | Tipo        | Free Tier              |
| --------------- | ----------- | ---------------------- |
| **EC2**         | t2.micro    | 750 hrs/mes gratis     |
| **RDS**         | db.t3.micro | 750 hrs/mes gratis     |
| **S3**          | Standard    | 5 GB gratis            |
| **Lambda**      | â€”           | 1M requests/mes gratis |
| **EventBridge** | â€”           | Gratis                 |

### Archivos de Infraestructura

```
infra/
â”œâ”€â”€ terraform/
â”‚   â”œâ”€â”€ main.tf              # VPC, Security Groups, providers
â”‚   â”œâ”€â”€ ec2.tf               # Instancia t2.micro
â”‚   â”œâ”€â”€ rds.tf               # PostgreSQL db.t3.micro
â”‚   â”œâ”€â”€ s3.tf                # Bucket para data y modelos
â”‚   â”œâ”€â”€ lambda.tf            # Trigger semanal del pipeline
â”‚   â””â”€â”€ variables.tfvars.example
â””â”€â”€ scripts/
    â””â”€â”€ setup_ec2.sh         # Bootstrap de la instancia
```

### Requisitos Previos

1. **Cuenta AWS** con Free Tier activo
2. **AWS CLI** configurado (`aws configure`)
3. **Terraform** instalado (v1.0+)
4. **Key Pair** de SSH creado en AWS

### Despliegue Paso a Paso

```bash
cd infra/terraform

cp variables.tfvars.example terraform.tfvars

terraform init

terraform plan -var-file=terraform.tfvars

terraform apply -var-file=terraform.tfvars
```

### Variables Requeridas

Editar `terraform.tfvars`:

```hcl
aws_region       = "us-east-1"
project_name     = "fair-play-shield"
environment      = "dev"
db_password      = "TU_PASSWORD_SEGURO"
ssh_key_name     = "tu-key-pair"
allowed_ssh_cidr = "TU_IP/32"
```

### Outputs del Despliegue

DespuÃ©s de `terraform apply`:

```
ec2_public_ip  = "3.xxx.xxx.xxx"
dashboard_url  = "http://3.xxx.xxx.xxx:8050"
mlflow_url     = "http://3.xxx.xxx.xxx:5001"
airflow_url    = "http://3.xxx.xxx.xxx:8080"
rds_endpoint   = "fair-play-shield-db.xxx.us-east-1.rds.amazonaws.com:5432"
s3_bucket_name = "fair-play-shield-data-xxxxxxxx"
```

### EjecuciÃ³n AutomÃ¡tica

El pipeline se ejecuta automÃ¡ticamente:

- **Frecuencia**: Cada lunes a las 6:00 AM UTC
- **Trigger**: EventBridge â†’ Lambda â†’ SSM â†’ EC2

Para ejecutar manualmente:

```bash
aws lambda invoke --function-name fair-play-shield-pipeline-trigger output.json
```

### CI/CD con GitHub Actions

El workflow `.github/workflows/deploy.yml` automatiza:

1. **Test**: Ejecuta tests en cada push
2. **Deploy**: En push a `main`, actualiza EC2 vÃ­a SSM

Secrets requeridos en GitHub:

- `AWS_ACCESS_KEY_ID`
- `AWS_SECRET_ACCESS_KEY`

### Destruir Infraestructura

```bash
terraform destroy -var-file=terraform.tfvars
```

---

## 24. Scripts de Entrenamiento y PredicciÃ³n

### Entrenamiento Manual

```bash
python scripts/train_model.py

python scripts/train_model.py \
  --data-path data/processed/my_data.csv \
  --model-prefix my_model \
  --output-scores data/processed/my_scores.csv
```

### PredicciÃ³n sobre Nuevos Datos

```bash
python scripts/predict.py --input data/new_matches.csv

python scripts/predict.py \
  --input data/new_matches.csv \
  --output data/scored_matches.csv \
  --model-prefix fps_leagues \
  --threshold 60
```

### Formato de Datos de Entrada

El CSV de entrada debe tener columnas similares a:

| Columna           | DescripciÃ³n              |
| ----------------- | ------------------------ |
| `date`            | Fecha del partido        |
| `home_team`       | Equipo local             |
| `away_team`       | Equipo visitante         |
| `home_goals`      | Goles local              |
| `away_goals`      | Goles visitante          |
| `odds_home_open`  | Cuota apertura local     |
| `odds_home_close` | Cuota cierre local       |
| ...               | (otras columnas de odds) |

---

## 25. GuÃ­a de InstalaciÃ³n Paso a Paso

### Requisitos Previos

- **Python 3.11+**
- **Docker & Docker Compose**
- **AWS CLI** configurado con credenciales
- **Terraform** >= 1.0
- **Git**

### OpciÃ³n A: Desarrollo Local

```bash
git clone https://github.com/eduzsantillan/fair_play_shield.git
cd fair_play_shield

python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt

cp .env.example .env

python main.py --step all --seasons 3

python dashboard/app.py
```

**Con Docker Compose (MLflow + Airflow):**

```bash
./scripts/init_airflow.sh
```

### OpciÃ³n B: Despliegue AWS Free Tier

#### Paso 1: Configurar AWS CLI

```bash
aws configure
# Ingresa: Access Key, Secret Key, Region (us-east-1)
```

#### Paso 2: Crear Key Pair en AWS

```bash
aws ec2 create-key-pair --key-name aws-dev --query 'KeyMaterial' --output text > ~/.ssh/aws-dev.pem
chmod 400 ~/.ssh/aws-dev.pem
```

#### Paso 3: Crear Repositorio ECR

```bash
aws ecr create-repository --repository-name fair-play-shield --region us-east-1
```

#### Paso 4: Construir y Subir Imagen Docker

```bash
aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin <ACCOUNT_ID>.dkr.ecr.us-east-1.amazonaws.com

docker buildx build --platform linux/amd64 -t <ACCOUNT_ID>.dkr.ecr.us-east-1.amazonaws.com/fair-play-shield:latest -f Dockerfile.prod . --push
```

#### Paso 5: Configurar Variables Terraform

```bash
cd infra/terraform
cp variables.tfvars.example terraform.tfvars
```

Editar `terraform.tfvars`:

```hcl
aws_region      = "us-east-1"
project_name    = "fair-play-shield"
environment     = "dev"
db_password     = "tu_password_seguro"  # Sin caracteres especiales (@, #, etc.)
ssh_key_name    = "aws-dev"
allowed_ssh_cidr = "0.0.0.0/0"  # O tu IP especÃ­fica
```

#### Paso 6: Desplegar Infraestructura

```bash
terraform init
terraform plan -var-file=terraform.tfvars
terraform apply -var-file=terraform.tfvars -auto-approve
```

#### Paso 7: Verificar Despliegue

```bash
terraform output

curl http://<EC2_PUBLIC_IP>:8050
```

#### Paso 8: Acceder por SSH (opcional)

```bash
ssh -i ~/.ssh/aws-dev.pem ec2-user@<EC2_PUBLIC_IP>
sudo docker ps
sudo docker logs fps-dashboard
```

### Redesplegar Cambios

```bash
docker buildx build --platform linux/amd64 -t <ACCOUNT_ID>.dkr.ecr.us-east-1.amazonaws.com/fair-play-shield:latest -f Dockerfile.prod . --push

ssh -i ~/.ssh/aws-dev.pem ec2-user@<EC2_PUBLIC_IP> "cd /home/ec2-user/fair_play_shield && sudo docker-compose pull && sudo docker-compose up -d"
```

### Destruir Infraestructura

```bash
cd infra/terraform
terraform destroy -var-file=terraform.tfvars
```

---

## 26. Arquitectura AWS Free Tier

### Componentes Desplegados

| Servicio        | Tipo                   | PropÃ³sito       |
| --------------- | ---------------------- | --------------- |
| **EC2**         | t3.micro (1GB RAM)     | Dashboard       |
| **RDS**         | db.t3.micro PostgreSQL | Base de datos   |
| **S3**          | Bucket                 | Datos y modelos |
| **ECR**         | Repositorio            | ImÃ¡genes Docker |
| **Lambda**      | FunciÃ³n                | Trigger semanal |
| **EventBridge** | Regla                  | Scheduler       |

### Limitaciones Free Tier

- **t3.micro** tiene solo 1GB RAM â†’ Solo Dashboard en EC2
- **MLflow y Airflow** deben correr localmente para desarrollo
- Para producciÃ³n completa, usar t3.small o superior

### URLs de Servicios

| Entorno   | Dashboard             | MLflow                | Airflow               |
| --------- | --------------------- | --------------------- | --------------------- |
| **Local** | http://localhost:8050 | http://localhost:5001 | http://localhost:8080 |
| **AWS**   | http://EC2_IP:8050    | Local                 | Local                 |

---

## 27. Troubleshooting

### EC2 no responde

```bash
aws ec2 reboot-instances --instance-ids <INSTANCE_ID>

ssh -i ~/.ssh/aws-dev.pem ec2-user@<EC2_IP> "sudo docker logs fps-dashboard"
```

### Error de arquitectura Docker

```bash
docker buildx build --platform linux/amd64 ...
```

### RDS conexiÃ³n rechazada

Verificar Security Group permite puerto 5432 desde EC2.

### Dashboard no accesible

```bash
ssh -i ~/.ssh/aws-dev.pem ec2-user@<EC2_IP> "sudo docker ps"
ssh -i ~/.ssh/aws-dev.pem ec2-user@<EC2_IP> "curl localhost:8050"
```
